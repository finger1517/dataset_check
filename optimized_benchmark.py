#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„è§†é¢‘æ•°æ®é›†åŸºå‡†æµ‹è¯•
è§£å†³å¹¶å‘æ•ˆç‡å’ŒHuggingFaceæ€§èƒ½é—®é¢˜
"""

import os
import time
import cv2
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import ray
from ray.data import Dataset as RayDataset
from datasets import Dataset as HFDataset
import pandas as pd
from typing import List, Tuple, Dict
import psutil
import gc
from multiprocessing import cpu_count
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import threading
import tempfile
import pickle

# è®¾ç½®è§†é¢‘æ•°æ®è·¯å¾„
VIDEO_DATA_PATH = "../video_data"

def find_all_mp4_files(base_path: str) -> List[str]:
    """é€’å½’æŸ¥æ‰¾æ‰€æœ‰mp4æ–‡ä»¶"""
    mp4_files = []
    for root, dirs, files in os.walk(base_path):
        for file in files:
            if file.endswith('.mp4'):
                mp4_files.append(os.path.join(root, file))
    return mp4_files

def extract_frames_from_video_optimized(video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """ä¼˜åŒ–çš„è§†é¢‘å¸§æå–å‡½æ•°"""
    cap = cv2.VideoCapture(video_path)
    
    # ä¼˜åŒ–ï¼šè®¾ç½®ç¼“å†²åŒºå¤§å°
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if total_frames == 0:
        cap.release()
        return np.zeros((num_frames, target_size[0], target_size[1], 3), dtype=np.uint8)
    
    # è®¡ç®—å‡åŒ€é‡‡æ ·çš„å¸§ç´¢å¼•
    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
    frames = []
    
    # ä¼˜åŒ–ï¼šé¢„åˆ†é…å†…å­˜
    frame_array = np.zeros((num_frames, target_size[0], target_size[1], 3), dtype=np.uint8)
    
    for i, frame_idx in enumerate(frame_indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if ret:
            # ä¼˜åŒ–ï¼šç›´æ¥å†™å…¥é¢„åˆ†é…çš„æ•°ç»„
            frame_resized = cv2.resize(frame, target_size)
            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
            frame_array[i] = frame_rgb
        # å¦‚æœè¯»å–å¤±è´¥ï¼Œä¿æŒé›¶å€¼ï¼ˆå·²é¢„åˆ†é…ï¼‰
    
    cap.release()
    return frame_array

# ==================== PyTorch Dataset ä¼˜åŒ–å®ç° ====================
class OptimizedPyTorchVideoDataset(Dataset):
    """ä¼˜åŒ–çš„PyTorchè§†é¢‘æ•°æ®é›†"""
    
    def __init__(self, video_paths: List[str], num_frames: int = 16, target_size: Tuple[int, int] = (224, 224), 
                 use_cache: bool = False):
        self.video_paths = video_paths
        self.num_frames = num_frames
        self.target_size = target_size
        self.use_cache = use_cache
        self.cache = {}
        
        # ä¼˜åŒ–çš„å˜æ¢
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def __len__(self):
        return len(self.video_paths)
    
    def __getitem__(self, idx):
        video_path = self.video_paths[idx]
        
        # ç¼“å­˜æœºåˆ¶
        if self.use_cache and video_path in self.cache:
            frames = self.cache[video_path]
        else:
            frames = extract_frames_from_video_optimized(video_path, self.num_frames, self.target_size)
            if self.use_cache:
                self.cache[video_path] = frames
        
        # ä¼˜åŒ–ï¼šæ‰¹é‡è½¬æ¢
        frames_tensor = torch.from_numpy(frames).float() / 255.0
        frames_tensor = frames_tensor.permute(0, 3, 1, 2)  # (T, H, W, C) -> (T, C, H, W)
        
        # æ ‡å‡†åŒ–
        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
        frames_tensor = (frames_tensor - mean) / std
        
        return {
            'frames': frames_tensor,
            'video_path': video_path,
            'video_name': os.path.basename(video_path)
        }

# ==================== Ray Dataset ä¼˜åŒ–å®ç° ====================
def process_video_ray_optimized(batch: Dict) -> Dict:
    """ä¼˜åŒ–çš„Rayæ•°æ®å¤„ç†å‡½æ•°"""
    video_paths = batch['video_path']
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=min(4, len(video_paths))) as executor:
        futures = {executor.submit(extract_frames_from_video_optimized, path): path 
                  for path in video_paths}
        
        processed_batch = {
            'frames': [],
            'video_path': [],
            'video_name': []
        }
        
        for future in futures:
            video_path = futures[future]
            try:
                frames = future.result()
                
                # ä¼˜åŒ–ï¼šå‘é‡åŒ–æ ‡å‡†åŒ–
                frames = frames.astype(np.float32) / 255.0
                frames = (frames - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])
                
                processed_batch['frames'].append(frames)
                processed_batch['video_path'].append(video_path)
                processed_batch['video_name'].append(os.path.basename(video_path))
                
            except Exception as e:
                print(f"å¤„ç†è§†é¢‘ {video_path} æ—¶å‡ºé”™: {str(e)}")
                empty_frames = np.zeros((16, 224, 224, 3), dtype=np.float32)
                processed_batch['frames'].append(empty_frames)
                processed_batch['video_path'].append(video_path)
                processed_batch['video_name'].append(os.path.basename(video_path))
    
    return processed_batch

# ==================== HuggingFace Dataset ä¼˜åŒ–å®ç° ====================
def process_video_hf_lightweight(example):
    """è½»é‡çº§HuggingFaceæ•°æ®å¤„ç†å‡½æ•°"""
    video_path = example['video_path']
    
    try:
        # åªè¿”å›è·¯å¾„ï¼Œå»¶è¿ŸåŠ è½½
        return {
            'video_path': video_path,
            'video_name': os.path.basename(video_path),
            'processed': False  # æ ‡è®°æœªå¤„ç†
        }
    except Exception as e:
        return {
            'video_path': video_path,
            'video_name': os.path.basename(video_path),
            'processed': False,
            'error': str(e)
        }

def create_hf_dataset_optimized(video_paths: List[str], use_lazy_loading: bool = True) -> HFDataset:
    """åˆ›å»ºä¼˜åŒ–çš„HuggingFaceæ•°æ®é›†"""
    data = [{'video_path': path} for path in video_paths]
    dataset = HFDataset.from_list(data)
    
    if use_lazy_loading:
        # ä½¿ç”¨å»¶è¿ŸåŠ è½½ï¼Œåªå¤„ç†å…ƒæ•°æ®
        return dataset.map(
            process_video_hf_lightweight, 
            num_proc=1,  # å‡å°‘è¿›ç¨‹æ•°
            desc="å‡†å¤‡è§†é¢‘å…ƒæ•°æ®"
        )
    else:
        # ä¼ ç»Ÿæ–¹å¼ï¼Œå®Œæ•´å¤„ç†
        return dataset.map(
            lambda x: {
                'frames': extract_frames_from_video_optimized(x['video_path']),
                'video_path': x['video_path'],
                'video_name': os.path.basename(x['video_path'])
            }, 
            num_proc=min(4, cpu_count()),
            desc="å¤„ç†è§†é¢‘æ•°æ®"
        )

# ==================== æ€§èƒ½æµ‹è¯•å‡½æ•° ====================
def measure_memory_usage():
    """æµ‹é‡å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # MB

def benchmark_pytorch_optimized(video_paths: List[str], batch_size: int = 8, num_workers: int = 4, 
                               use_cache: bool = False) -> Dict:
    """æµ‹è¯•ä¼˜åŒ–çš„PyTorchæ•°æ®é›†æ€§èƒ½"""
    print(f"ğŸ”¥ æµ‹è¯•ä¼˜åŒ–PyTorchæ•°æ®é›† (workers={num_workers}, batch_size={batch_size}, cache={use_cache})...")
    
    start_memory = measure_memory_usage()
    start_time = time.time()
    
    dataset = OptimizedPyTorchVideoDataset(video_paths, use_cache=use_cache)
    dataloader = DataLoader(
        dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available(),
        persistent_workers=True if num_workers > 0 else False,
        prefetch_factor=2 if num_workers > 0 else 2
    )
    
    processed_samples = 0
    batch_count = 0
    
    for batch in dataloader:
        batch_count += 1
        processed_samples += len(batch['frames'])
        # æ¨¡æ‹Ÿå¤„ç†
        _ = batch['frames'].mean()
        
        if batch_count % 10 == 0:
            print(f"   å·²å¤„ç† {processed_samples} ä¸ªæ ·æœ¬...")
    
    end_time = time.time()
    end_memory = measure_memory_usage()
    
    return {
        'name': f'PyTorchä¼˜åŒ–ç‰ˆ ({num_workers}workers, cache={use_cache})',
        'total_time': end_time - start_time,
        'samples_processed': processed_samples,
        'samples_per_second': processed_samples / (end_time - start_time),
        'memory_usage_mb': end_memory - start_memory,
        'peak_memory_mb': end_memory,
        'num_workers': num_workers,
        'batch_size': batch_size
    }

def benchmark_ray_optimized(video_paths: List[str], batch_size: int = 8, num_workers: int = 4) -> Dict:
    """æµ‹è¯•ä¼˜åŒ–çš„Rayæ•°æ®é›†æ€§èƒ½"""
    print(f"âš¡ æµ‹è¯•ä¼˜åŒ–Rayæ•°æ®é›† (workers={num_workers}, batch_size={batch_size})...")
    
    start_memory = measure_memory_usage()
    start_time = time.time()
    
    data = [{'video_path': path} for path in video_paths]
    ds = ray.data.from_items(data)
    dataset = ds.map_batches(
        process_video_ray_optimized, 
        batch_size=batch_size,
        num_cpus=2,
        concurrency=num_workers
    )
    
    processed_samples = 0
    batch_count = 0
    
    for batch in dataset.iter_batches(batch_size=batch_size):
        batch_count += 1
        processed_samples += len(batch['frames'])
        _ = np.mean([np.mean(frames) for frames in batch['frames']])
        
        if batch_count % 10 == 0:
            print(f"   å·²å¤„ç† {processed_samples} ä¸ªæ ·æœ¬...")
    
    end_time = time.time()
    end_memory = measure_memory_usage()
    
    return {
        'name': f'Rayä¼˜åŒ–ç‰ˆ ({num_workers}workers)',
        'total_time': end_time - start_time,
        'samples_processed': processed_samples,
        'samples_per_second': processed_samples / (end_time - start_time),
        'memory_usage_mb': end_memory - start_memory,
        'peak_memory_mb': end_memory,
        'num_workers': num_workers,
        'batch_size': batch_size
    }

def benchmark_hf_optimized(video_paths: List[str], batch_size: int = 8, use_lazy_loading: bool = True) -> Dict:
    """æµ‹è¯•ä¼˜åŒ–çš„HuggingFaceæ•°æ®é›†æ€§èƒ½"""
    mode = "å»¶è¿ŸåŠ è½½" if use_lazy_loading else "å®Œæ•´å¤„ç†"
    print(f"ğŸ¤— æµ‹è¯•ä¼˜åŒ–HuggingFaceæ•°æ®é›† ({mode}, batch_size={batch_size})...")
    
    start_memory = measure_memory_usage()
    start_time = time.time()
    
    dataset = create_hf_dataset_optimized(video_paths, use_lazy_loading=use_lazy_loading)
    
    processed_samples = 0
    batch_count = 0
    
    if use_lazy_loading:
        # å»¶è¿ŸåŠ è½½æ¨¡å¼ï¼šåœ¨è¿­ä»£æ—¶æ‰å¤„ç†è§†é¢‘
        for i in range(0, len(dataset), batch_size):
            batch_count += 1
            batch_paths = dataset[i:i+batch_size]['video_path']
            
            # å®æ—¶å¤„ç†è§†é¢‘
            if isinstance(batch_paths, list):
                for path in batch_paths:
                    frames = extract_frames_from_video_optimized(path)
                    _ = np.mean(frames)
                    processed_samples += 1
            else:
                frames = extract_frames_from_video_optimized(batch_paths)
                _ = np.mean(frames)
                processed_samples += 1
            
            if batch_count % 10 == 0:
                print(f"   å·²å¤„ç† {processed_samples} ä¸ªæ ·æœ¬...")
    else:
        # ä¼ ç»Ÿæ¨¡å¼
        for i in range(0, len(dataset), batch_size):
            batch_count += 1
            batch = dataset[i:i+batch_size]
            
            if isinstance(batch['frames'], list):
                processed_samples += len(batch['frames'])
                _ = np.mean([np.mean(frames) for frames in batch['frames']])
            else:
                processed_samples += 1
                _ = np.mean(batch['frames'])
            
            if batch_count % 10 == 0:
                print(f"   å·²å¤„ç† {processed_samples} ä¸ªæ ·æœ¬...")
    
    end_time = time.time()
    end_memory = measure_memory_usage()
    
    return {
        'name': f'HuggingFaceä¼˜åŒ–ç‰ˆ ({mode})',
        'total_time': end_time - start_time,
        'samples_processed': processed_samples,
        'samples_per_second': processed_samples / (end_time - start_time),
        'memory_usage_mb': end_memory - start_memory,
        'peak_memory_mb': end_memory,
        'batch_size': batch_size,
        'lazy_loading': use_lazy_loading
    }

def run_optimized_comparison(video_paths: List[str]) -> List[Dict]:
    """è¿è¡Œä¼˜åŒ–çš„æ€§èƒ½æ¯”è¾ƒ"""
    results = []
    
    print(f"ğŸš€ å¼€å§‹ä¼˜åŒ–æ€§èƒ½æµ‹è¯• (CPUæ ¸å¿ƒæ•°: {cpu_count()})")
    
    # æµ‹è¯•PyTorchä¸åŒé…ç½®
    for num_workers in [2, 4, 8]:
        if num_workers <= cpu_count():
            # æ— ç¼“å­˜ç‰ˆæœ¬
            result = benchmark_pytorch_optimized(video_paths, batch_size=8, num_workers=num_workers, use_cache=False)
            results.append(result)
            
            # ç¼“å­˜ç‰ˆæœ¬ï¼ˆä»…æµ‹è¯•ä¸€æ¬¡ï¼‰
            if num_workers == 4:
                result_cached = benchmark_pytorch_optimized(video_paths, batch_size=8, num_workers=num_workers, use_cache=True)
                results.append(result_cached)
    
    # æµ‹è¯•Rayä¸åŒé…ç½®
    for num_workers in [2, 4, 8]:
        if num_workers <= cpu_count():
            result = benchmark_ray_optimized(video_paths, batch_size=8, num_workers=num_workers)
            results.append(result)
    
    # æµ‹è¯•HuggingFaceä¼˜åŒ–ç‰ˆæœ¬
    # å»¶è¿ŸåŠ è½½ç‰ˆæœ¬
    result_lazy = benchmark_hf_optimized(video_paths, batch_size=8, use_lazy_loading=True)
    results.append(result_lazy)
    
    # å®Œæ•´å¤„ç†ç‰ˆæœ¬ï¼ˆä»…ç”¨å°‘é‡æ•°æ®æµ‹è¯•ï¼‰
    small_paths = video_paths[:20]  # åªç”¨20ä¸ªæ–‡ä»¶æµ‹è¯•
    result_full = benchmark_hf_optimized(small_paths, batch_size=8, use_lazy_loading=False)
    results.append(result_full)
    
    return results

def print_optimized_results(results: List[Dict]):
    """æ‰“å°ä¼˜åŒ–æµ‹è¯•ç»“æœ"""
    print("\n" + "="*100)
    print("ğŸ“Š ä¼˜åŒ–åçš„è§†é¢‘æ•°æ®é›†å¤„ç†æ€§èƒ½æ¯”è¾ƒç»“æœ")
    print("="*100)
    
    for result in results:
        print(f"\nğŸ¯ {result['name']}:")
        print(f"   æ€»å¤„ç†æ—¶é—´: {result['total_time']:.2f} ç§’")
        print(f"   å¤„ç†æ ·æœ¬æ•°: {result['samples_processed']}")
        print(f"   å¤„ç†é€Ÿåº¦: {result['samples_per_second']:.2f} æ ·æœ¬/ç§’")
        print(f"   å†…å­˜ä½¿ç”¨: {result['memory_usage_mb']:.2f} MB")
        print(f"   å³°å€¼å†…å­˜: {result['peak_memory_mb']:.2f} MB")
    
    # æ‰¾å‡ºæœ€ä½³é…ç½®
    fastest = max(results, key=lambda x: x['samples_per_second'])
    most_efficient_memory = min(results, key=lambda x: x['memory_usage_mb'])
    
    print(f"\nğŸ† æœ€å¿«é…ç½®: {fastest['name']}")
    print(f"   å¤„ç†é€Ÿåº¦: {fastest['samples_per_second']:.2f} æ ·æœ¬/ç§’")
    
    print(f"\nğŸ’¾ æœ€çœå†…å­˜é…ç½®: {most_efficient_memory['name']}")
    print(f"   å†…å­˜ä½¿ç”¨: {most_efficient_memory['memory_usage_mb']:.2f} MB")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ å¼€å§‹ä¼˜åŒ–çš„è§†é¢‘æ•°æ®é›†å¤„ç†æ•ˆèƒ½æ¯”è¾ƒæµ‹è¯•...")
    print(f"ğŸ’» ç³»ç»Ÿä¿¡æ¯: {cpu_count()} CPUæ ¸å¿ƒ")
    
    # åˆå§‹åŒ–Ray
    if not ray.is_initialized():
        ray.init(
            num_cpus=cpu_count(),
            ignore_reinit_error=True,
            include_dashboard=False
        )
    
    # æŸ¥æ‰¾æ‰€æœ‰è§†é¢‘æ–‡ä»¶
    print("ğŸ“ æ­£åœ¨æœç´¢è§†é¢‘æ–‡ä»¶...")
    video_paths = find_all_mp4_files(VIDEO_DATA_PATH)
    
    if not video_paths:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•mp4æ–‡ä»¶ï¼")
        return
    
    # ä½¿ç”¨é€‚é‡çš„æ–‡ä»¶è¿›è¡Œæµ‹è¯•
    test_video_paths = video_paths[:min(100, len(video_paths))]
    print(f"ğŸ“¹ æ‰¾åˆ° {len(video_paths)} ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œå°†æµ‹è¯•å‰ {len(test_video_paths)} ä¸ª")
    
    try:
        # è¿è¡Œä¼˜åŒ–æ¯”è¾ƒæµ‹è¯•
        results = run_optimized_comparison(test_video_paths)
        
        # æ‰“å°ç»“æœ
        print_optimized_results(results)
        
        # ä¿å­˜ç»“æœåˆ°CSV
        df = pd.DataFrame(results)
        df.to_csv('optimized_benchmark_results.csv', index=False)
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° optimized_benchmark_results.csv")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†Rayèµ„æº
        if ray.is_initialized():
            ray.shutdown()

if __name__ == "__main__":
    main() 