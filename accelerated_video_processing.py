#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠ é€Ÿè§†é¢‘å¤„ç†æ¨¡å—
ä½¿ç”¨GPUã€Numba JITå’Œå¤šçº¿ç¨‹ä¼˜åŒ–è§†é¢‘å¸§æå–
"""

import os
import time
import cv2
import numpy as np
from typing import List, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

# GPUç›¸å…³å¯¼å…¥
try:
    import cupy as cp
    HAS_CUPY = True
    print("âœ… CuPyå¯ç”¨ï¼Œå°†ä½¿ç”¨GPUåŠ é€Ÿ")
except ImportError:
    HAS_CUPY = False
    print("âš ï¸ CuPyä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUå¤„ç†")

# Numba JITç›¸å…³å¯¼å…¥
try:
    from numba import jit, cuda
    import numba as nb
    HAS_NUMBA = True
    print("âœ… Numbaå¯ç”¨ï¼Œå°†ä½¿ç”¨JITç¼–è¯‘")
except ImportError:
    HAS_NUMBA = False
    print("âš ï¸ Numbaä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ™®é€šPython")

# FFmpegç›¸å…³å¯¼å…¥ï¼ˆæ›´å¿«çš„è§†é¢‘è§£ç ï¼‰
try:
    import ffmpeg
    HAS_FFMPEG = True
    print("âœ… FFmpeg-pythonå¯ç”¨ï¼Œå°†ä½¿ç”¨FFmpegè§£ç ")
except ImportError:
    HAS_FFMPEG = False
    print("âš ï¸ FFmpeg-pythonä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨OpenCV")

# ==================== GPUåŠ é€Ÿå®ç° ====================

def extract_frames_gpu(video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """ä½¿ç”¨GPUåŠ é€Ÿçš„è§†é¢‘å¸§æå–"""
    if not HAS_CUPY:
        return extract_frames_cpu_optimized(video_path, num_frames, target_size)
    
    try:
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if total_frames == 0:
            cap.release()
            return np.zeros((num_frames, target_size[0], target_size[1], 3), dtype=np.uint8)
        
        # è®¡ç®—å‡åŒ€é‡‡æ ·çš„å¸§ç´¢å¼•
        frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
        
        # é¢„åˆ†é…GPUå†…å­˜
        frames_gpu = cp.zeros((num_frames, target_size[0], target_size[1], 3), dtype=cp.uint8)
        
        for i, frame_idx in enumerate(frame_indices):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            
            if ret:
                # CPUä¸Šè°ƒæ•´å¤§å°ï¼ˆOpenCVåœ¨CPUä¸Šæ›´å¿«ï¼‰
                frame_resized = cv2.resize(frame, target_size)
                frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
                
                # è½¬ç§»åˆ°GPUè¿›è¡Œåç»­å¤„ç†
                frame_gpu = cp.asarray(frame_rgb)
                frames_gpu[i] = frame_gpu
        
        cap.release()
        
        # å°†ç»“æœè½¬å›CPU
        return cp.asnumpy(frames_gpu)
        
    except Exception as e:
        print(f"GPUå¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
        return extract_frames_cpu_optimized(video_path, num_frames, target_size)

@cuda.jit if HAS_NUMBA else lambda x: x
def normalize_frames_gpu(frames, mean, std):
    """GPUä¸Šçš„å¸§æ ‡å‡†åŒ–"""
    i, j, k, c = cuda.grid(4)
    if i < frames.shape[0] and j < frames.shape[1] and k < frames.shape[2] and c < frames.shape[3]:
        frames[i, j, k, c] = (frames[i, j, k, c] / 255.0 - mean[c]) / std[c]

# ==================== Numba JITä¼˜åŒ–å®ç° ====================

@jit(nopython=True, parallel=True) if HAS_NUMBA else lambda x: x
def resize_frame_numba(frame: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
    """ä½¿ç”¨Numba JITä¼˜åŒ–çš„å¸§å¤§å°è°ƒæ•´"""
    # æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„åŒçº¿æ€§æ’å€¼å®ç°
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒOpenCVçš„resizeé€šå¸¸æ›´å¿«æ›´å‡†ç¡®
    h_old, w_old = frame.shape[:2]
    h_new, w_new = target_size
    
    # é¢„åˆ†é…è¾“å‡ºæ•°ç»„
    if frame.ndim == 3:
        resized = np.zeros((h_new, w_new, frame.shape[2]), dtype=frame.dtype)
    else:
        resized = np.zeros((h_new, w_new), dtype=frame.dtype)
    
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    x_ratio = w_old / w_new
    y_ratio = h_old / h_new
    
    for i in range(h_new):
        for j in range(w_new):
            # æœ€è¿‘é‚»æ’å€¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
            x = int(j * x_ratio)
            y = int(i * y_ratio)
            
            # è¾¹ç•Œæ£€æŸ¥
            x = min(x, w_old - 1)
            y = min(y, h_old - 1)
            
            if frame.ndim == 3:
                resized[i, j] = frame[y, x]
            else:
                resized[i, j] = frame[y, x]
    
    return resized

@jit(nopython=True, parallel=True) if HAS_NUMBA else lambda x: x
def normalize_frames_numba(frames: np.ndarray) -> np.ndarray:
    """ä½¿ç”¨Numba JITä¼˜åŒ–çš„å¸§æ ‡å‡†åŒ–"""
    # ImageNetæ ‡å‡†åŒ–å‚æ•°
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    
    # è½¬æ¢ä¸ºfloatå¹¶æ ‡å‡†åŒ–
    normalized = frames.astype(np.float32) / 255.0
    
    for i in range(frames.shape[0]):  # éå†å¸§
        for j in range(frames.shape[1]):  # é«˜åº¦
            for k in range(frames.shape[2]):  # å®½åº¦
                for c in range(3):  # RGBé€šé“
                    normalized[i, j, k, c] = (normalized[i, j, k, c] - mean[c]) / std[c]
    
    return normalized

# ==================== FFmpegä¼˜åŒ–å®ç° ====================

def extract_frames_ffmpeg(video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """ä½¿ç”¨FFmpegè¿›è¡Œæ›´å¿«çš„è§†é¢‘è§£ç """
    if not HAS_FFMPEG:
        return extract_frames_cpu_optimized(video_path, num_frames, target_size)
    
    try:
        # è·å–è§†é¢‘ä¿¡æ¯
        probe = ffmpeg.probe(video_path)
        video_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')
        total_frames = int(video_info['nb_frames']) if 'nb_frames' in video_info else 1000
        duration = float(video_info['duration']) if 'duration' in video_info else 10.0
        
        # è®¡ç®—æ—¶é—´æˆ³
        timestamps = np.linspace(0, duration, num_frames)
        
        frames = []
        for timestamp in timestamps:
            try:
                # ä½¿ç”¨FFmpegç›´æ¥è·³è½¬åˆ°æŒ‡å®šæ—¶é—´æˆ³
                out = (
                    ffmpeg
                    .input(video_path, ss=timestamp)
                    .filter('scale', target_size[0], target_size[1])
                    .output('pipe:', vframes=1, format='rawvideo', pix_fmt='rgb24')
                    .run(capture_stdout=True, quiet=True)
                )
                
                # è§£æåŸå§‹RGBæ•°æ®
                frame = np.frombuffer(out[0], np.uint8).reshape(target_size[1], target_size[0], 3)
                frames.append(frame)
                
            except Exception as e:
                # å¦‚æœæŸä¸ªå¸§æå–å¤±è´¥ï¼Œæ·»åŠ é›¶å¸§
                frames.append(np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8))
        
        return np.array(frames)
        
    except Exception as e:
        print(f"FFmpegå¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°OpenCV: {e}")
        return extract_frames_cpu_optimized(video_path, num_frames, target_size)

# ==================== CPUå¤šçº¿ç¨‹ä¼˜åŒ–å®ç° ====================

def extract_single_frame(args):
    """æå–å•ä¸ªå¸§çš„å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹"""
    video_path, frame_idx, target_size = args
    
    cap = cv2.VideoCapture(video_path)
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
    ret, frame = cap.read()
    cap.release()
    
    if ret:
        frame_resized = cv2.resize(frame, target_size)
        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
        return frame_rgb
    else:
        return np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8)

def extract_frames_multiprocess(video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œæå–å¸§"""
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()
    
    if total_frames == 0:
        return np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    # è®¡ç®—å¸§ç´¢å¼•
    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
    
    # å‡†å¤‡å‚æ•°
    args = [(video_path, idx, target_size) for idx in frame_indices]
    
    # ä½¿ç”¨è¿›ç¨‹æ± 
    # with ProcessPoolExecutor(max_workers=min(num_frames, mp.cpu_count())) as executor:
    with ProcessPoolExecutor(max_workers=1) as executor:
        frames = list(executor.map(extract_single_frame, args))
    
    return np.array(frames)

# ==================== CPUä¼˜åŒ–å®ç°ï¼ˆåŸºçº¿ï¼‰====================

def extract_frames_cpu_optimized(video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """CPUä¼˜åŒ–ç‰ˆæœ¬çš„è§†é¢‘å¸§æå–"""
    cap = cv2.VideoCapture(video_path)
    
    # ä¼˜åŒ–ï¼šè®¾ç½®ç¼“å†²åŒºå¤§å°
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if total_frames == 0:
        cap.release()
        return np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    # è®¡ç®—å¸§ç´¢å¼•
    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
    
    # é¢„åˆ†é…æ•°ç»„
    frames = np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    for i, frame_idx in enumerate(frame_indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        
        if ret:
            # ç›´æ¥å†™å…¥é¢„åˆ†é…çš„æ•°ç»„
            frame_resized = cv2.resize(frame, target_size)
            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
            frames[i] = frame_rgb
    
    cap.release()
    return frames

# ==================== æ™ºèƒ½æ–¹æ³•é€‰æ‹© ====================

class AcceleratedVideoProcessor:
    """æ™ºèƒ½è§†é¢‘å¤„ç†å™¨ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³åŠ é€Ÿæ–¹æ³•"""
    
    def __init__(self):
        self.methods = []
        self._setup_methods()
    
    def _setup_methods(self):
        """è®¾ç½®å¯ç”¨çš„å¤„ç†æ–¹æ³•"""
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        if HAS_CUPY:
            self.methods.append(('GPU', extract_frames_gpu))
        
        if HAS_FFMPEG:
            self.methods.append(('FFmpeg', extract_frames_ffmpeg))
        
        # å¤šè¿›ç¨‹æ–¹æ³•ï¼ˆå¯¹äºå¤§è§†é¢‘æ–‡ä»¶æ•ˆæœå¥½ï¼‰
        self.methods.append(('MultiProcess', extract_frames_multiprocess))
        
        # CPUä¼˜åŒ–æ–¹æ³•ï¼ˆåŸºçº¿ï¼‰
        self.methods.append(('CPU', extract_frames_cpu_optimized))
        
        print(f"å¯ç”¨çš„åŠ é€Ÿæ–¹æ³•: {[name for name, _ in self.methods]}")
    
    def benchmark_methods(self, video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)):
        """åŸºå‡†æµ‹è¯•æ‰€æœ‰å¯ç”¨æ–¹æ³•"""
        print(f"\nğŸ”¬ åŸºå‡†æµ‹è¯•è§†é¢‘: {os.path.basename(video_path)}")
        print("=" * 60)
        
        results = {}
        
        for method_name, method_func in self.methods:
            try:
                print(f"æµ‹è¯• {method_name}...")
                start_time = time.time()
                
                frames = method_func(video_path, num_frames, target_size)
                
                end_time = time.time()
                processing_time = end_time - start_time
                
                results[method_name] = {
                    'time': processing_time,
                    'fps': num_frames / processing_time,
                    'frames_shape': frames.shape,
                    'success': True
                }
                
                print(f"   âœ… {method_name}: {processing_time:.3f}ç§’ ({num_frames/processing_time:.1f} FPS)")
                
            except Exception as e:
                results[method_name] = {
                    'time': float('inf'),
                    'fps': 0,
                    'error': str(e),
                    'success': False
                }
                print(f"   âŒ {method_name}: å¤±è´¥ - {e}")
        
        # æ‰¾å‡ºæœ€å¿«çš„æ–¹æ³•
        successful_methods = {k: v for k, v in results.items() if v['success']}
        if successful_methods:
            fastest = min(successful_methods.items(), key=lambda x: x[1]['time'])
            print(f"\nğŸ† æœ€å¿«æ–¹æ³•: {fastest[0]} ({fastest[1]['fps']:.1f} FPS)")
        
        return results
    
    def extract_frames(self, video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224), 
                      method: Optional[str] = None) -> np.ndarray:
        """æå–è§†é¢‘å¸§ï¼Œè‡ªåŠ¨æˆ–æ‰‹åŠ¨é€‰æ‹©æ–¹æ³•"""
        if method:
            # ä½¿ç”¨æŒ‡å®šæ–¹æ³•
            method_func = next((func for name, func in self.methods if name.lower() == method.lower()), None)
            if method_func:
                return method_func(video_path, num_frames, target_size)
            else:
                print(f"æœªæ‰¾åˆ°æ–¹æ³• {method}ï¼Œä½¿ç”¨é»˜è®¤æ–¹æ³•")
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ–¹æ³•ï¼ˆé€šå¸¸æ˜¯æœ€å¿«çš„ï¼‰
        for method_name, method_func in self.methods:
            try:
                return method_func(video_path, num_frames, target_size)
            except Exception as e:
                print(f"{method_name} å¤±è´¥: {e}")
                continue
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é›¶æ•°ç»„
        return np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)

# ==================== æµ‹è¯•å’Œæ¼”ç¤º ====================

def benchmark_all_methods(video_paths: List[str]):
    """å¯¹å¤šä¸ªè§†é¢‘æ–‡ä»¶è¿›è¡Œå…¨é¢åŸºå‡†æµ‹è¯•"""
    processor = AcceleratedVideoProcessor()
    
    print("ğŸš€ å¼€å§‹å…¨é¢æ€§èƒ½æµ‹è¯•")
    print("=" * 80)
    
    # ä½¿ç”¨ä¸åŒå¤§å°çš„è§†é¢‘è¿›è¡Œæµ‹è¯•
    test_videos = video_paths[:10] if len(video_paths) >= 3 else video_paths
    
    all_results = {}
    
    for video_path in test_videos:
        print(f"\nğŸ“¹ æµ‹è¯•è§†é¢‘: {os.path.basename(video_path)}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        cap.release()
        
        print(f"   åˆ†è¾¨ç‡: {width}x{height}, å¸§æ•°: {frame_count}, FPS: {fps:.1f}")
        
        results = processor.benchmark_methods(video_path)
        all_results[video_path] = results
    
    # æ±‡æ€»ç»“æœ
    print("\nğŸ“Š æ€§èƒ½æ±‡æ€»:")
    print("=" * 80)
    
    method_totals = {}
    for video_results in all_results.values():
        for method_name, result in video_results.items():
            if result['success']:
                if method_name not in method_totals:
                    method_totals[method_name] = []
                method_totals[method_name].append(result['fps'])
    
    for method_name, fps_list in method_totals.items():
        avg_fps = np.mean(fps_list)
        print(f"ğŸ¯ {method_name}: å¹³å‡ {avg_fps:.1f} FPS")
    
    return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("âš¡ åŠ é€Ÿè§†é¢‘å¤„ç†æµ‹è¯•")
    
    # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
    from video_dataset_comparison import find_all_mp4_files
    video_paths = find_all_mp4_files("../video_data")
    
    if not video_paths:
        print("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        return
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    results = benchmark_all_methods(video_paths)
    
    # æ¼”ç¤ºä½¿ç”¨
    processor = AcceleratedVideoProcessor()
    
    print("\nğŸ¬ å®é™…ä½¿ç”¨ç¤ºä¾‹:")
    test_video = video_paths[0]
    
    start_time = time.time()
    frames = processor.extract_frames(test_video, num_frames=16, target_size=(224, 224))
    end_time = time.time()
    
    print(f"âœ… æå– {frames.shape[0]} å¸§ï¼Œè€—æ—¶ {end_time - start_time:.3f}ç§’")
    print(f"ğŸ“ å¸§å°ºå¯¸: {frames.shape}")

if __name__ == "__main__":
    main() 