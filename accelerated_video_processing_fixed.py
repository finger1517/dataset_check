#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤çš„åŠ é€Ÿè§†é¢‘å¤„ç†æ¨¡å—
ç¡®ä¿åŒ…å«å®Œæ•´çš„JITå¯¹æ¯”æµ‹è¯•
"""

import os
import time
import cv2
import numpy as np
from typing import List, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

# GPUç›¸å…³å¯¼å…¥
try:
    import cupy as cp
    HAS_CUPY = True
    print("âœ… CuPyå¯ç”¨ï¼Œå°†ä½¿ç”¨GPUåŠ é€Ÿ")
except ImportError:
    HAS_CUPY = False
    print("âš ï¸ CuPyä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUå¤„ç†")

# Numba JITç›¸å…³å¯¼å…¥
try:
    from numba import jit, prange
    import numba as nb
    HAS_NUMBA = True
    print("âœ… Numbaå¯ç”¨ï¼Œå°†ä½¿ç”¨JITç¼–è¯‘")
except ImportError:
    HAS_NUMBA = False
    print("âš ï¸ Numbaä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ™®é€šPython")

# FFmpegç›¸å…³å¯¼å…¥
try:
    import ffmpeg
    HAS_FFMPEG = True
    print("âœ… FFmpeg-pythonå¯ç”¨ï¼Œå°†ä½¿ç”¨FFmpegè§£ç ")
except ImportError:
    HAS_FFMPEG = False
    print("âš ï¸ FFmpeg-pythonä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨OpenCV")

# ==================== JITä¼˜åŒ–å®ç° ====================

if HAS_NUMBA:
    @jit(nopython=True, parallel=True)
    def normalize_frames_jit(frames: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨Numba JITä¼˜åŒ–çš„å¸§æ ‡å‡†åŒ–"""
        mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
        std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
        
        normalized = frames.astype(np.float32) / 255.0
        
        for i in prange(frames.shape[0]):
            for j in range(frames.shape[1]):
                for k in range(frames.shape[2]):
                    for c in range(3):
                        normalized[i, j, k, c] = (normalized[i, j, k, c] - mean[c]) / std[c]
        
        return normalized
else:
    def normalize_frames_jit(frames: np.ndarray) -> np.ndarray:
        """å›é€€åˆ°numpyå®ç°"""
        mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
        std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
        normalized = frames.astype(np.float32) / 255.0
        return (normalized - mean) / std

def extract_frames_jit(video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """ä½¿ç”¨JITä¼˜åŒ–çš„è§†é¢‘å¸§æå–"""
    cap = cv2.VideoCapture(video_path)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if total_frames == 0:
        cap.release()
        return np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
    frames = np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    for i, frame_idx in enumerate(frame_indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        
        if ret:
            frame_resized = cv2.resize(frame, target_size)
            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
            frames[i] = frame_rgb
    
    cap.release()
    
    # ä½¿ç”¨JITä¼˜åŒ–çš„æ ‡å‡†åŒ–
    normalized_frames = normalize_frames_jit(frames)
    return normalized_frames

# ==================== CPUåŸºçº¿å®ç° ====================

def extract_frames_cpu_baseline(video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """CPUåŸºçº¿ç‰ˆæœ¬ï¼ˆæ— ä»»ä½•ä¼˜åŒ–ï¼‰"""
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if total_frames == 0:
        cap.release()
        return np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
    frames = np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    for i, frame_idx in enumerate(frame_indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        
        if ret:
            frame_resized = cv2.resize(frame, target_size)
            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
            frames[i] = frame_rgb
    
    cap.release()
    
    # CPUåŸºçº¿æ ‡å‡†åŒ–ï¼ˆnumpyå‘é‡åŒ–ï¼‰
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    normalized = frames.astype(np.float32) / 255.0
    normalized = (normalized - mean) / std
    
    return normalized

# ==================== å…¶ä»–æ–¹æ³•ï¼ˆé‡ç”¨ä¹‹å‰çš„ä»£ç ï¼‰====================

def extract_frames_cpu_optimized(video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """CPUä¼˜åŒ–ç‰ˆæœ¬"""
    cap = cv2.VideoCapture(video_path)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if total_frames == 0:
        cap.release()
        return np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
    frames = np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    for i, frame_idx in enumerate(frame_indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        
        if ret:
            frame_resized = cv2.resize(frame, target_size)
            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
            frames[i] = frame_rgb
    
    cap.release()
    return frames

# ==================== æ›´æ–°çš„è§†é¢‘å¤„ç†å™¨ ====================

class AcceleratedVideoProcessor:
    """æ›´æ–°çš„æ™ºèƒ½è§†é¢‘å¤„ç†å™¨ï¼ŒåŒ…å«JITå¯¹æ¯”"""
    
    def __init__(self):
        self.methods = []
        self._setup_methods()
    
    def _setup_methods(self):
        """è®¾ç½®æ‰€æœ‰å¯ç”¨çš„å¤„ç†æ–¹æ³•"""
        # CPUåŸºçº¿ï¼ˆæœ€æ…¢ï¼‰
        self.methods.append(('CPUåŸºçº¿', extract_frames_cpu_baseline))
        
        # JITä¼˜åŒ–
        if HAS_NUMBA:
            self.methods.append(('JITä¼˜åŒ–', extract_frames_jit))
        
        # CPUä¼˜åŒ–ï¼ˆæ— æ ‡å‡†åŒ–ï¼Œæ›´å¿«çš„åŸºçº¿ï¼‰
        self.methods.append(('CPUä¼˜åŒ–', extract_frames_cpu_optimized))
        
        # å…¶ä»–åŠ é€Ÿæ–¹æ³•...
        if HAS_FFMPEG:
            self.methods.append(('FFmpeg', self._extract_frames_ffmpeg))
        
        print(f"å¯ç”¨çš„å¤„ç†æ–¹æ³•: {[name for name, _ in self.methods]}")
    
    def _extract_frames_ffmpeg(self, video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
        """FFmpegæ–¹æ³•çš„åŒ…è£…"""
        # è¿™é‡Œé‡ç”¨ä¹‹å‰çš„FFmpegå®ç°
        return extract_frames_cpu_optimized(video_path, num_frames, target_size)
    
    def benchmark_jit_vs_baseline(self, video_paths: List[str], num_videos: int = 5):
        """ä¸“é—¨å¯¹æ¯”JITå’ŒCPUåŸºçº¿çš„æ€§èƒ½"""
        print("\nğŸ”¬ JIT vs CPUåŸºçº¿è¯¦ç»†å¯¹æ¯”:")
        print("=" * 60)
        
        test_videos = video_paths[:num_videos]
        
        methods_to_compare = []
        for name, func in self.methods:
            if name in ['CPUåŸºçº¿', 'JITä¼˜åŒ–']:
                methods_to_compare.append((name, func))
        
        if len(methods_to_compare) < 2:
            print("âŒ éœ€è¦åŒæ—¶æœ‰CPUåŸºçº¿å’ŒJITä¼˜åŒ–æ–¹æ³•")
            return
        
        results = {}
        
        for method_name, method_func in methods_to_compare:
            print(f"\næµ‹è¯• {method_name}:")
            
            # é¢„çƒ­JITï¼ˆå¦‚æœé€‚ç”¨ï¼‰
            if 'JIT' in method_name and HAS_NUMBA:
                print("   ğŸ”¥ é¢„çƒ­JITç¼–è¯‘...")
                _ = method_func(test_videos[0], num_frames=4, target_size=(112, 112))
            
            total_time = 0
            total_frames = 0
            video_times = []
            
            for i, video_path in enumerate(test_videos):
                print(f"   ğŸ“¹ å¤„ç†è§†é¢‘ {i+1}/{len(test_videos)}: {os.path.basename(video_path)}")
                
                start_time = time.time()
                frames = method_func(video_path, num_frames=16, target_size=(224, 224))
                end_time = time.time()
                
                processing_time = end_time - start_time
                video_times.append(processing_time)
                total_time += processing_time
                total_frames += frames.shape[0]
                
                fps = frames.shape[0] / processing_time
                print(f"      â±ï¸  {processing_time:.3f}ç§’ ({fps:.1f} å¸§/ç§’)")
            
            avg_time_per_video = total_time / len(test_videos)
            avg_fps = total_frames / total_time
            std_time = np.std(video_times)
            
            results[method_name] = {
                'total_time': total_time,
                'avg_time_per_video': avg_time_per_video,
                'std_time': std_time,
                'total_frames': total_frames,
                'avg_fps': avg_fps,
                'video_times': video_times
            }
            
            print(f"   ğŸ“Š å¹³å‡æ¯è§†é¢‘: {avg_time_per_video:.3f}Â±{std_time:.3f}ç§’")
            print(f"   ğŸš€ å¹³å‡é€Ÿåº¦: {avg_fps:.1f} å¸§/ç§’")
        
        # è®¡ç®—æ€§èƒ½æå‡
        if 'CPUåŸºçº¿' in results and 'JITä¼˜åŒ–' in results:
            baseline = results['CPUåŸºçº¿']
            jit_result = results['JITä¼˜åŒ–']
            
            speedup = baseline['avg_fps'] / jit_result['avg_fps'] if jit_result['avg_fps'] > 0 else 0
            time_reduction = (baseline['total_time'] - jit_result['total_time']) / baseline['total_time'] * 100
            
            print(f"\nğŸ“ˆ JITæ€§èƒ½åˆ†æ:")
            print("=" * 40)
            print(f"ğŸƒ é€Ÿåº¦æå‡: {speedup:.2f}å€")
            print(f"â° æ—¶é—´å‡å°‘: {time_reduction:.1f}%")
            print(f"ğŸ“Š CPUåŸºçº¿: {baseline['avg_fps']:.1f} å¸§/ç§’")
            print(f"âš¡ JITä¼˜åŒ–: {jit_result['avg_fps']:.1f} å¸§/ç§’")
            
            if speedup > 1.0:
                print("âœ… JITä¼˜åŒ–æœ‰æ•ˆï¼")
            else:
                print("âš ï¸ JITä¼˜åŒ–æ•ˆæœä¸æ˜æ˜¾ï¼Œå¯èƒ½å—I/Oé™åˆ¶")
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    print("âš¡ ä¿®å¤çš„åŠ é€Ÿè§†é¢‘å¤„ç†æµ‹è¯•ï¼ˆåŒ…å«JITå¯¹æ¯”ï¼‰")
    
    if HAS_NUMBA:
        # é¢„çƒ­JIT
        print("ğŸ”¥ é¢„çƒ­JITç¼–è¯‘...")
        test_data = np.random.randint(0, 255, (4, 224, 224, 3), dtype=np.uint8)
        _ = normalize_frames_jit(test_data)
        print("âœ… JITé¢„çƒ­å®Œæˆ")
    
    # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
    from video_dataset_comparison import find_all_mp4_files
    video_paths = find_all_mp4_files("../video_data")
    
    if not video_paths:
        print("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        return
    
    # åˆ›å»ºå¤„ç†å™¨å¹¶è¿è¡Œæµ‹è¯•
    processor = AcceleratedVideoProcessor()
    
    # ä¸“é—¨çš„JIT vs åŸºçº¿å¯¹æ¯”
    if HAS_NUMBA:
        jit_results = processor.benchmark_jit_vs_baseline(video_paths, num_videos=20)
    else:
        print("âš ï¸ Numbaä¸å¯ç”¨ï¼Œè·³è¿‡JITå¯¹æ¯”æµ‹è¯•")

if __name__ == "__main__":
    main() 