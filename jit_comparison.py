#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Numba JIT vs CPUåŸºçº¿æ€§èƒ½å¯¹æ¯”æµ‹è¯•
ä¸“é—¨æ¯”è¾ƒJITç¼–è¯‘ä¼˜åŒ–çš„æ•ˆæœ
"""

import os
import time
import cv2
import numpy as np
from typing import List, Tuple
import matplotlib.pyplot as plt

# Numbaå¯¼å…¥
try:
    from numba import jit, prange
    import numba as nb
    HAS_NUMBA = True
    print("âœ… Numbaå¯ç”¨ï¼Œå°†è¿›è¡ŒJITå¯¹æ¯”æµ‹è¯•")
except ImportError:
    HAS_NUMBA = False
    print("âŒ Numbaä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒJITæµ‹è¯•")
    exit(1)

# ==================== CPUåŸºçº¿å®ç°ï¼ˆæ— JITï¼‰====================

def extract_frames_cpu_baseline(video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """CPUåŸºçº¿ç‰ˆæœ¬ï¼ˆæ— JITä¼˜åŒ–ï¼‰"""
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if total_frames == 0:
        cap.release()
        return np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
    frames = np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    for i, frame_idx in enumerate(frame_indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        
        if ret:
            frame_resized = cv2.resize(frame, target_size)
            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
            frames[i] = frame_rgb
    
    cap.release()
    
    # CPUåŸºçº¿æ ‡å‡†åŒ–ï¼ˆPythonåŸç”Ÿï¼‰
    normalized_frames = normalize_frames_python(frames)
    return normalized_frames

def normalize_frames_python(frames: np.ndarray) -> np.ndarray:
    """PythonåŸç”Ÿæ ‡å‡†åŒ–ï¼ˆæ— JITï¼‰"""
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    
    # ä½¿ç”¨numpyå‘é‡åŒ–æ“ä½œ
    normalized = frames.astype(np.float32) / 255.0
    normalized = (normalized - mean) / std
    
    return normalized

def normalize_frames_python_loops(frames: np.ndarray) -> np.ndarray:
    """ä½¿ç”¨Pythonå¾ªç¯çš„æ ‡å‡†åŒ–ï¼ˆæ¨¡æ‹Ÿæœ€æ…¢æƒ…å†µï¼‰"""
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    
    normalized = frames.astype(np.float32) / 255.0
    
    # ä½¿ç”¨Pythonå¾ªç¯ï¼ˆå¾ˆæ…¢ï¼‰
    for i in range(frames.shape[0]):
        for j in range(frames.shape[1]):
            for k in range(frames.shape[2]):
                for c in range(3):
                    normalized[i, j, k, c] = (normalized[i, j, k, c] - mean[c]) / std[c]
    
    return normalized

# ==================== Numba JITä¼˜åŒ–å®ç° ====================

@jit(nopython=True)
def normalize_frames_jit(frames: np.ndarray) -> np.ndarray:
    """ä½¿ç”¨Numba JITä¼˜åŒ–çš„æ ‡å‡†åŒ–"""
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    
    normalized = frames.astype(np.float32) / 255.0
    
    for i in range(frames.shape[0]):
        for j in range(frames.shape[1]):
            for k in range(frames.shape[2]):
                for c in range(3):
                    normalized[i, j, k, c] = (normalized[i, j, k, c] - mean[c]) / std[c]
    
    return normalized

@jit(nopython=True, parallel=True)
def normalize_frames_jit_parallel(frames: np.ndarray) -> np.ndarray:
    """ä½¿ç”¨Numba JITå¹¶è¡Œä¼˜åŒ–çš„æ ‡å‡†åŒ–"""
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    
    normalized = frames.astype(np.float32) / 255.0
    
    # ä½¿ç”¨prangeè¿›è¡Œå¹¶è¡Œå¤„ç†
    for i in prange(frames.shape[0]):
        for j in range(frames.shape[1]):
            for k in range(frames.shape[2]):
                for c in range(3):
                    normalized[i, j, k, c] = (normalized[i, j, k, c] - mean[c]) / std[c]
    
    return normalized

@jit(nopython=True)
def resize_frame_jit(frame: np.ndarray, new_height: int, new_width: int) -> np.ndarray:
    """ä½¿ç”¨JITä¼˜åŒ–çš„ç®€å•å›¾åƒç¼©æ”¾ï¼ˆæœ€è¿‘é‚»ï¼‰"""
    old_height, old_width = frame.shape[:2]
    
    # é¢„åˆ†é…è¾“å‡ºæ•°ç»„
    if frame.ndim == 3:
        resized = np.zeros((new_height, new_width, frame.shape[2]), dtype=frame.dtype)
    else:
        resized = np.zeros((new_height, new_width), dtype=frame.dtype)
    
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    y_ratio = old_height / new_height
    x_ratio = old_width / new_width
    
    for i in range(new_height):
        for j in range(new_width):
            # æœ€è¿‘é‚»æ’å€¼
            y = min(int(i * y_ratio), old_height - 1)
            x = min(int(j * x_ratio), old_width - 1)
            
            if frame.ndim == 3:
                resized[i, j] = frame[y, x]
            else:
                resized[i, j] = frame[y, x]
    
    return resized

def extract_frames_jit(video_path: str, num_frames: int = 16, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """ä½¿ç”¨JITä¼˜åŒ–çš„è§†é¢‘å¸§æå–"""
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if total_frames == 0:
        cap.release()
        return np.zeros((num_frames, target_size[1], target_size[0], 3), dtype=np.uint8)
    
    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
    frames = []
    
    for frame_idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        
        if ret:
            # ä»ç„¶ä½¿ç”¨OpenCVè¿›è¡Œè§†é¢‘è§£ç å’Œé¢œè‰²è½¬æ¢ï¼ˆè¿™éƒ¨åˆ†å¾ˆéš¾ç”¨JITä¼˜åŒ–ï¼‰
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # ä½¿ç”¨JITä¼˜åŒ–çš„ç¼©æ”¾
            frame_resized = resize_frame_jit(frame_rgb, target_size[1], target_size[0])
            frames.append(frame_resized)
        else:
            frames.append(np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8))
    
    cap.release()
    
    frames_array = np.array(frames)
    
    # ä½¿ç”¨JITä¼˜åŒ–çš„æ ‡å‡†åŒ–
    normalized_frames = normalize_frames_jit_parallel(frames_array)
    return normalized_frames

# ==================== åŸºå‡†æµ‹è¯•å‡½æ•° ====================

def benchmark_normalization_methods(frames: np.ndarray):
    """æ¯”è¾ƒä¸åŒæ ‡å‡†åŒ–æ–¹æ³•çš„æ€§èƒ½"""
    print("\nğŸ”¬ æ ‡å‡†åŒ–æ–¹æ³•æ€§èƒ½å¯¹æ¯”:")
    print("=" * 60)
    
    methods = [
        ("Pythonå‘é‡åŒ–", normalize_frames_python),
        ("Pythonå¾ªç¯", normalize_frames_python_loops),
        ("Numba JIT", normalize_frames_jit),
        ("Numba JITå¹¶è¡Œ", normalize_frames_jit_parallel),
    ]
    
    results = {}
    
    for method_name, method_func in methods:
        print(f"æµ‹è¯• {method_name}...")
        
        # é¢„çƒ­JITç¼–è¯‘ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
        if "JIT" in method_name:
            _ = method_func(frames[:1])  # é¢„çƒ­
        
        # å®é™…æµ‹è¯•
        times = []
        for _ in range(5):  # è¿è¡Œ5æ¬¡å–å¹³å‡
            start_time = time.time()
            result = method_func(frames.copy())
            end_time = time.time()
            times.append(end_time - start_time)
        
        avg_time = np.mean(times)
        std_time = np.std(times)
        
        results[method_name] = {
            'avg_time': avg_time,
            'std_time': std_time,
            'fps': frames.shape[0] / avg_time
        }
        
        print(f"   â±ï¸  å¹³å‡æ—¶é—´: {avg_time:.4f}Â±{std_time:.4f}ç§’")
        print(f"   ğŸš€ å¤„ç†é€Ÿåº¦: {frames.shape[0]/avg_time:.1f} å¸§/ç§’")
    
    # æ‰¾å‡ºæœ€å¿«çš„æ–¹æ³•
    fastest = min(results.items(), key=lambda x: x[1]['avg_time'])
    baseline = results["Pythonå‘é‡åŒ–"]
    
    print(f"\nğŸ† æœ€å¿«æ–¹æ³•: {fastest[0]}")
    print(f"ğŸ“ˆ ç›¸æ¯”åŸºçº¿æå‡: {baseline['avg_time']/fastest[1]['avg_time']:.2f}å€")
    
    return results

def benchmark_full_pipeline(video_paths: List[str]):
    """æ¯”è¾ƒå®Œæ•´çš„è§†é¢‘å¤„ç†ç®¡é“"""
    print("\nğŸ¬ å®Œæ•´è§†é¢‘å¤„ç†ç®¡é“å¯¹æ¯”:")
    print("=" * 60)
    
    methods = [
        ("CPUåŸºçº¿", extract_frames_cpu_baseline),
        ("JITä¼˜åŒ–", extract_frames_jit),
    ]
    
    results = {}
    test_videos = video_paths[:5]  # æµ‹è¯•å‰5ä¸ªè§†é¢‘
    
    for method_name, method_func in methods:
        print(f"\næµ‹è¯• {method_name}...")
        
        total_time = 0
        total_frames = 0
        
        for video_path in test_videos:
            print(f"   å¤„ç†: {os.path.basename(video_path)}")
            
            start_time = time.time()
            frames = method_func(video_path, num_frames=16, target_size=(224, 224))
            end_time = time.time()
            
            processing_time = end_time - start_time
            total_time += processing_time
            total_frames += frames.shape[0]
            
            print(f"      â±ï¸  {processing_time:.3f}ç§’ ({frames.shape[0]/processing_time:.1f} å¸§/ç§’)")
        
        avg_fps = total_frames / total_time
        
        results[method_name] = {
            'total_time': total_time,
            'total_frames': total_frames,
            'avg_fps': avg_fps
        }
        
        print(f"   ğŸ“Š æ€»è®¡: {total_time:.3f}ç§’, å¹³å‡ {avg_fps:.1f} å¸§/ç§’")
    
    # è®¡ç®—æ€§èƒ½æå‡
    if "CPUåŸºçº¿" in results and "JITä¼˜åŒ–" in results:
        baseline_fps = results["CPUåŸºçº¿"]["avg_fps"]
        jit_fps = results["JITä¼˜åŒ–"]["avg_fps"]
        improvement = jit_fps / baseline_fps
        
        print(f"\nğŸ“ˆ JITä¼˜åŒ–æå‡: {improvement:.2f}å€")
        print(f"ğŸ¯ ä» {baseline_fps:.1f} FPS æå‡åˆ° {jit_fps:.1f} FPS")
    
    return results

def plot_performance_comparison(norm_results: dict, pipeline_results: dict):
    """ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
    try:
        # æ ‡å‡†åŒ–æ€§èƒ½å¯¹æ¯”
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # æ ‡å‡†åŒ–æ–¹æ³•å¯¹æ¯”
        methods = list(norm_results.keys())
        times = [norm_results[method]['avg_time'] for method in methods]
        
        bars1 = ax1.bar(methods, times, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])
        ax1.set_title('æ ‡å‡†åŒ–æ–¹æ³•æ€§èƒ½å¯¹æ¯”')
        ax1.set_ylabel('å¤„ç†æ—¶é—´ (ç§’)')
        ax1.tick_params(axis='x', rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, time_val in zip(bars1, times):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{time_val:.4f}s', ha='center', va='bottom')
        
        # å®Œæ•´ç®¡é“å¯¹æ¯”
        if pipeline_results:
            pipeline_methods = list(pipeline_results.keys())
            fps_values = [pipeline_results[method]['avg_fps'] for method in pipeline_methods]
            
            bars2 = ax2.bar(pipeline_methods, fps_values, color=['#FF6B6B', '#45B7D1'])
            ax2.set_title('å®Œæ•´è§†é¢‘å¤„ç†ç®¡é“å¯¹æ¯”')
            ax2.set_ylabel('å¤„ç†é€Ÿåº¦ (å¸§/ç§’)')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, fps_val in zip(bars2, fps_values):
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height,
                        f'{fps_val:.1f} FPS', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig('jit_performance_comparison.png', dpi=300, bbox_inches='tight')
        print("\nğŸ“Š æ€§èƒ½å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜ä¸º jit_performance_comparison.png")
        
    except ImportError:
        print("âš ï¸ matplotlibä¸å¯ç”¨ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")

def warm_up_jit():
    """é¢„çƒ­JITç¼–è¯‘"""
    print("ğŸ”¥ é¢„çƒ­JITç¼–è¯‘...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_frames = np.random.randint(0, 255, (4, 224, 224, 3), dtype=np.uint8)
    
    # é¢„çƒ­å„ä¸ªJITå‡½æ•°
    _ = normalize_frames_jit(test_frames)
    _ = normalize_frames_jit_parallel(test_frames)
    _ = resize_frame_jit(test_frames[0], 112, 112)
    
    print("âœ… JITé¢„çƒ­å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("âš¡ Numba JIT vs CPUåŸºçº¿æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 50)
    
    if not HAS_NUMBA:
        print("âŒ Numbaä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
        return
    
    # é¢„çƒ­JIT
    warm_up_jit()
    
    # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
    from video_dataset_comparison import find_all_mp4_files
    video_paths = find_all_mp4_files("../video_data")
    
    if not video_paths:
        print("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        return
    
    # 1. å…ˆæµ‹è¯•æ ‡å‡†åŒ–æ–¹æ³•
    print("\nğŸ“¹ åŠ è½½æµ‹è¯•æ•°æ®...")
    test_video = video_paths[0]
    cap = cv2.VideoCapture(test_video)
    
    # è¯»å–ä¸€äº›å¸§ç”¨äºæ ‡å‡†åŒ–æµ‹è¯•
    frames = []
    for i in range(32):  # è¯»å–32å¸§
        ret, frame = cap.read()
        if ret:
            frame = cv2.resize(frame, (224, 224))
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(frame)
    cap.release()
    
    if frames:
        frames_array = np.array(frames, dtype=np.uint8)
        norm_results = benchmark_normalization_methods(frames_array)
    else:
        print("âŒ æ— æ³•è¯»å–æµ‹è¯•å¸§")
        norm_results = {}
    
    # 2. æµ‹è¯•å®Œæ•´çš„è§†é¢‘å¤„ç†ç®¡é“
    pipeline_results = benchmark_full_pipeline(video_paths)
    
    # 3. ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨
    plot_performance_comparison(norm_results, pipeline_results)
    
    # 4. æ€»ç»“
    print("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print("=" * 50)
    print("ğŸ”¹ JITç¼–è¯‘åœ¨è®¡ç®—å¯†é›†å‹æ“ä½œï¼ˆå¦‚æ ‡å‡†åŒ–ï¼‰ä¸­æ•ˆæœæ˜¾è‘—")
    print("ğŸ”¹ å¯¹äºI/Oå¯†é›†å‹æ“ä½œï¼ˆå¦‚è§†é¢‘è§£ç ï¼‰ï¼ŒJITæå‡æœ‰é™")
    print("ğŸ”¹ å¹¶è¡ŒJITåœ¨å¤šæ ¸CPUä¸Šèƒ½æä¾›é¢å¤–çš„æ€§èƒ½æå‡")
    print("ğŸ”¹ é¦–æ¬¡è¿è¡ŒJITå‡½æ•°ä¼šæœ‰ç¼–è¯‘å¼€é”€ï¼Œåç»­è°ƒç”¨é€Ÿåº¦å¾ˆå¿«")

if __name__ == "__main__":
    main() 